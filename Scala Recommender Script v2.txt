import org.apache.log4j.Logger
import org.apache.log4j.Level
Logger.getLogger("org").setLevel(Level.OFF)
Logger.getLogger("akka").setLevel(Level.OFF)

import org.apache.spark.sql._
import org.apache.spark.sql.types._
import org.apache.spark.sql.functions._

import org.apache.spark.rdd._
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._

import sqlContext.implicits._
import java.util.Random
import scala.io.Source

///// feature transformation
import org.apache.spark.ml.feature._
import org.apache.spark.ml.classification._
import org.apache.spark.ml.evaluation._
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.clustering.KMeans
import org.apache.spark.mllib.linalg.Vectors

---2.
// Runs any HiveQL command
sqlContext.sql("use dinesafe");

// Creates a DataFrame pointing to the specified Hive table 
val dinesafe = sqlContext.table("Dinesafe")
val profile = sqlContext.table("Profile")

dinesafe.printSchema()
profile.printSchema()

---3.
// transform Cuisine Type to numeric index
val dinesafe_ind = new StringIndexer().setInputCol("cuisine_type").setOutputCol("cuisine_type_ind").fit(dinesafe)
val dinesafe_ind_trans = dinesafe_ind.transform(dinesafe)
dinesafe_ind_trans.printSchema()

---4. 
//list distinct values
var distinct_df = dinesafe_ind_trans.select($"cuisine_type",$"cuisine_type_ind").distinct.show(20)

---5.
// 0 - Cafe
val isCafe = udf( (cuisine_type_ind: Double) => { if (cuisine_type_ind == 0) 1 else 0})
// 1 - North American
val isNorth_American = udf( (cuisine_type_ind: Double) => { if (cuisine_type_ind == 1) 1  else 0})
// 2 - Deli
val isDeli = udf( (cuisine_type_ind: Double) => { if (cuisine_type_ind == 2) 1 else 0})
// 3 - European
val isEuropean = udf( (cuisine_type_ind: Double) => {if (cuisine_type_ind == 3) 1 else 0})
// 4 - Far Eastern
val isFar_Eastern = udf( (cuisine_type_ind: Double) => { if (cuisine_type_ind == 4) 1 else 0 })
// 5 - Mediterranean
val isMediterranean = udf( (cuisine_type_ind: Double) => { if (cuisine_type_ind == 5) 1 else 0})
// 6 - South East Asian
val isSE_Asian = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 6) 1 else 0})
// 7 - Bar
val isBar = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 7) 1 else 0})
// 8 - Juicery 
val isJuicery = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 8) 1 else 0 })
// 9 - South Asian
val isSAsian = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 9) 1 else 0 })
// 10 - Caribbean
val isCaribbean = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 10) 1 else 0 })
// 11 - Pastries
val isPastries = udf( (cuisine_type_ind: Double) =>  {  if (cuisine_type_ind == 11) 1 else 0 })
// 12 - Latin American 
val isLatin_American = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 12) 1  else 0 })
// 13 - Dessert
val isDessert = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 13) 1 else 0})
// 14 - Middle Eastern
val isMiddle_Eastern = udf( (cuisine_type_ind: Double) => {if (cuisine_type_ind == 14) 1 else 0})
// 15 - African
val isAfrican = udf( (cuisine_type_ind: Double) => {if (cuisine_type_ind == 15) 1 else 0})
// 16 - Bakeries 
val isBakeries = udf( (cuisine_type_ind: Double) => {  if (cuisine_type_ind == 16) 1 else 0})

val df2 = dinesafe_ind_trans.withColumn("African", isAfrican($"cuisine_type_ind"))
                 .withColumn("Bar", isBar($"cuisine_type_ind"))
                 .withColumn("Cafe", isCafe($"cuisine_type_ind"))
                 .withColumn("Caribbean", isCaribbean($"cuisine_type_ind"))
                 .withColumn("Deli", isDeli($"cuisine_type_ind"))
                 .withColumn("Dessert", isDessert($"cuisine_type_ind"))
                 .withColumn("European", isEuropean($"cuisine_type_ind"))
                 .withColumn("Far_Eastern", isFar_Eastern($"cuisine_type_ind"))
                 .withColumn("Pastries", isPastries($"cuisine_type_ind"))
                 .withColumn("South_Asian", isSAsian($"cuisine_type_ind"))
                 .withColumn("South_East_Asian", isSE_Asian($"cuisine_type_ind"))
                 .withColumn("Latin_American", isLatin_American($"cuisine_type_ind"))
                 .withColumn("Mediterranean", isMediterranean($"cuisine_type_ind"))
                 .withColumn("Middle_Eastern", isMiddle_Eastern($"cuisine_type_ind"))
                 .withColumn("North_American", isNorth_American($"cuisine_type_ind"))
                 .withColumn("Juicery", isJuicery($"cuisine_type_ind"))
//var df4 = df2.select($"establishment_id",$"review",$"value",$"African",$"Bar",$"Cafe",$"Caribbean",$"Deli",$"Dessert",$"European",$"Far Eastern",$"Pastries",
//$"South Asian",$"South East Asian",$"Mediterranean",$"Middle Eastern",$"North American",$"Latin American")
df2.printSchema

---6. 
val df3 = df2.select ($"establishment_id".cast(IntegerType).alias("establishment_id"),$"African",$"Bar",$"Cafe",$"Caribbean",$"Deli",$"Dessert",$"European",$"Far_Eastern",$"Pastries",$"South_Asian",$"South_East_Asian",$"Latin_American", $"Mediterranean",$"Middle_Eastern",$"North_American",$"Juicery")
df3.count
df3.orderBy(asc("establishment_id")).show(10)

// Remove duplicate rows
val df4 = df3.dropDuplicates()
df4.count
df4.orderBy(asc("establishment_id")).show(10)

---7.
//Create a vector 
val features = Array("African","Bar","Cafe","Caribbean","Deli","Dessert","European","Far_Eastern","Pastries","South_Asian","South_East_Asian","Latin_American", "Mediterranean","Middle_Eastern","North_American","Juicery")

//Create a feature
val features_vec = new VectorAssembler()
                .setInputCols(features)
                .setOutputCol("features")
                .transform(df4)

//Show features_vec
   val finalRDD = features_vec.select($"establishment_id", $"features").orderBy(asc("establishment_id"))
   finalRDD.show()
   finalRDD.cache

---8.
// Split data to 80/20
val Array(trainRDD, testRDD) = features_vec.randomSplit(Array(0.8,0.2))
val training_data = trainRDD.count
val testing_data = testRDD.count
val training_data_ratio = trainRDD.count/features_vec.count().toDouble
val testing_data_ratio = testRDD.count/features_vec.count().toDouble
//training.show()
//testing.show()

----9.
// Trains a k-means model.
val kmeans = new KMeans().setK(16).setSeed(1L)
val model = kmeans.fit(trainRDD)

// Evaluate clustering by computing Within Set Sum of Squared Errors.
val WSSSE = model.computeCost(trainRDD)
println("K Mean Cost : " + WSSSE)
println("Input data rows : " + trainRDD.count()) 

----10 
// Print cluster centers
model.clusterCenters.foreach{println}

----11.
// Show train model
val transformed =  model.transform(trainRDD)
//transformed.collect().foreach(println)
val v = transformed.select("establishment_id","prediction","African", "Bar", "Cafe", "Caribbean", "Deli", "Dessert", "European", "Far_Eastern", "Pastries", "South_Asian", "South_East_Asian", "Latin_American", "Mediterranean", "Middle_Eastern", "North_American", "Juicery").show()
